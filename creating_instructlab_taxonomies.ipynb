{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7ih7e5O6rX_",
        "tags": []
      },
      "source": [
        "# Creating InstructLab Taxonomies\n",
        "\n",
        "<ul>\n",
        "<li>Contributors: InstructLab team and IBM Research Technology Education team:\n",
        "<li>Questions and support: kochel@us.ibm.com, IBM.Research.JupyterLab@ibm.com\n",
        "<li>Release date: 2025-03-20\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ics9GgZ-6rYB",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Summary\n",
        "This Jupyter notebook facilitates compiling taxonomies for InstructLab, an open source AI project that enables knowledge and skills contributions to Large Language Models (LLMs). This notebook performs the following:\n",
        "1. Accepts one or more of Question and Answer (QNA) files as input\n",
        "1. Places the QNA files in the desired palce in a taxonomy\n",
        "1. Verifies the taxonomy by running the ilab dif function\n",
        "1. Creates a Tar file of the taxonomy that can be used for Synthetic Data Generation\n",
        "1. Downloads the Tar file or provides it to the RedHat AI Instructlab Service\n",
        "\n",
        "This notebook can be run with the free Colab environment. You can run this notebook either:\n",
        "- Running All Cells by selecting Runtime->Run all\n",
        "- Cell by cell by selecting the arrow on each code cell and running them sequentially.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_SZDBZgMVa"
      },
      "source": [
        "# Step 1. Set up Environment and Show Paramsters\n",
        "\n",
        "Replicate the ilab data repository containing the pip requirements and data files.\n",
        "\n",
        "\n",
        "After selecting parameters, the remainder of this notebook can be run either:\n",
        "- Running All Cells by selecting Runtime->Run cell and below\n",
        "- Cell by cell by selecting the arrow on each code cell and running them sequentially.\n",
        "\n",
        "## Step Select InstructLab Parameters\n",
        "\n",
        "Run this next cell, select the following parameters, then follow the direction in the next text cell to run the notebook.\n",
        "\n",
        "We've provided question-and-answer files for these datasets: \"2024 Oscar Awards Ceremony\" and \"Quantum Roadmap and Patterns\" and \"Artificial Intelligence Agents\". Feel free to choose one of these datasets, or select your own custom dataset in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E0Z6oO2L_3I"
      },
      "outputs": [],
      "source": [
        "# Install these items first to avoid a later reset\n",
        "!pip install psutil==7.0.0 pillow==10.4.0 --quiet\n",
        "\n",
        "import os\n",
        "os.chdir('/content/')\n",
        "if os.path.exists(\"ilab\"):\n",
        "    !rm -rf ilab\n",
        "!git clone https://github.com/KenOcheltree/ilab-test.git --quiet --recurse-submodules ilab\n",
        "\n",
        "# Run this second cell to show parameters\n",
        "import ipywidgets as widgets\n",
        "data_set = widgets.ToggleButtons(\n",
        "    options=['2024 Oscars', 'Quantum', 'Agentic AI', 'Your Content 1', 'Your Content 2'],\n",
        "    description='Dataset:', style={\"button_width\": \"auto\"}\n",
        ")\n",
        "tar=widgets.ToggleButtons(options=['Yes','No'],description='Create Tar:',style={\"button_width\":\"auto\"})\n",
        "download=widgets.ToggleButtons(options=['Yes','No'],description='Download:',style={\"button_width\":\"auto\"}\n",
        ")\n",
        "print(\"\\nSelect the Dataset for this run:\")\n",
        "display(data_set)\n",
        "print(\"Select what to do with the taxonomy after creation:\")\n",
        "tar.value=\"Yes\"\n",
        "display(tar)\n",
        "download.value=\"No\"\n",
        "display(download)\n",
        "print(\"After selecting the parameters, select the next cell and then choose Runtime->Run cell and below\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dmB_IVBPkZ1",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Step 2. Provide Taxonomy data\n",
        "\n",
        "You can provide your own InstructLab QNA files for processing in this step. You may want to run this notebook once with an existing dataset before creating your own to understand the Tasonomy creation flow.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Follow these steps to add your own dataset:\n",
        "1. Create your own qna.yaml files following the directions on the InstructLab taxonomy [readme](https://github.com/instructlab/taxonomy).\n",
        "1. Create a questions.txt file with related sample questions to use on inferencing.\n",
        "1. Add your qna.yaml and sample questions.txt files to the /content/ilab/data/your_content_1 folder or the /content/ilab/data/your_content_2 folder by dragging and dropping them in the desired folder.\n",
        "1. Double click on the /content/ilab/config.json file to edit and specify the qna_location where your data resides within the Dewey Decimal classification system. Close and save the config.json file.\n",
        "1. You can now specify to run with your own data by selecting **Your Content 1** or **Your Content 2** in the next code cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv5uMvQ-a-ZF",
        "tags": []
      },
      "source": [
        "## 1.4 Complete Environment Set Up and Optionally Run All\n",
        "This code cell installs the remainder of the reuired pip packages and takes a few minutes to run.\n",
        "\n",
        "The first half of the cell wraps the code cell output for all following cells for ease of reading.\n",
        "\n",
        "Check the InstructLab version.\n",
        "\n",
        "If you perform **Runtime->Run cell and below** on this cell, the rest of notebook will take about 10 minutes to run. After running, it will present a prompt for providing questions to the pre-trained and trained models to test improvements in the model.\n",
        "\n",
        "\n",
        "## Step 1.6 Perform Imports and Configure InstructLab\n",
        "\n",
        "### Create InstructLab config file\n",
        "The InstructLab configuration is captured in the *config.yaml* file. This step creates the config.yaml file and sets:\n",
        "- **taxomony_path = taxonomy** - the root location of the taxonomy is set to the taxonomy folder in instructlab-latest\n",
        "- **model_path = models/merlinite-7b-lab-Q4_K_M.gguf** - the default model is set to merlinite\n",
        "\n",
        "**Note:** The default directories for InstructLab are the following. If you initialize InstructLab on your own system, it will default to the following:\n",
        "* **Downloaded Models:**  ~/.cache/instructlab/models/ - Contains all downloaded large language models, including the saved output of ones you generate with ilab.\n",
        "* **Synthetic Data:** ~/.local/share/instructlab/datasets/ - Contains data output from the SDG phase, built on modifications to the taxonomy repository.\n",
        "* **Taxonomy:** ~/.local/share/instructlab/taxonomy/ - Contains the skill and knowledge data.\n",
        "* **Training Output:** ~/.local/share/instructlab/checkpoints/ - Contains the output of the training process.\n",
        "* **config.yaml:** ~/.config/instructlab/config.yaml - Contains the config.yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX9s4XZx6rYF"
      },
      "outputs": [],
      "source": [
        "# Run the rest of the notebook by selecting this third cell and choosing \"Runtime->Run cell and below\"\n",
        "\n",
        "# Wrap Code cell output\n",
        "from IPython.display import HTML, display\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "#Install the ibmcloud plugin\n",
        "!curl -fsSL https://clis.cloud.ibm.com/install/linux | sh\n",
        "!ibmcloud plugin install ilab -f\n",
        "\n",
        "#Install the rest of the requirements\n",
        "os.chdir('/content/ilab/')\n",
        "print(\"Starting directory: \"+ os.getcwd())\n",
        "!pip install -r requirements.txt --quiet\n",
        "!ilab system info\n",
        "\n",
        "from IPython.display import Image, display\n",
        "#import json\n",
        "#import subprocess\n",
        "import shutil\n",
        "import ruamel.yaml\n",
        "\n",
        "#Initialize ilab\n",
        "base_dir=\"/root/\"\n",
        "taxonomy_path='taxonomy'\n",
        "model_path = \"models/granite-7b-lab-Q4_K_M.gguf\"\n",
        "\n",
        "## Define the file name\n",
        "file_name = \"config.yaml\"\n",
        "if os.path.exists(file_name):\n",
        "    os.remove(file_name)\n",
        "    print(f\"ilab was already initialized. {file_name} has been deleted. Reinitialized\")\n",
        "else:\n",
        "    print(f\"ilab was not initialized yet. {file_name} does not exist.\")\n",
        "\n",
        "##Remove old data\n",
        "if os.path.exists(\"taxonomy\"):\n",
        "    print(\"removing taxonomy\")\n",
        "    shutil.rmtree(\"taxonomy\")\n",
        "if os.path.exists(base_dir+\".cache/instructlab\"):\n",
        "    print(\"removing \" + base_dir+\".cache/instructlab\")\n",
        "    shutil.rmtree(base_dir+\".cache/instructlab\")\n",
        "if os.path.exists(base_dir+\".config/instructlab\"):\n",
        "    print(\"removing \" + base_dir+\".config/instructlab\")\n",
        "    shutil.rmtree(base_dir+\".config/instructlab\")\n",
        "if os.path.exists(base_dir+\".local/share/instructlab\"):\n",
        "    print(\"removing \" + base_dir+\".local/share/instructlab\")\n",
        "    shutil.rmtree(base_dir+\".local/share/instructlab\")\n",
        "print(\"Initialized ilab\")\n",
        "command = f\"\"\"\n",
        "ilab config init<<EOF\n",
        "{taxonomy_path}\n",
        "Y\n",
        "{model_path}\n",
        "0\n",
        "EOF\n",
        "\"\"\"\n",
        "\n",
        "## Using the ! operator to run the command\n",
        "!echo \"Running ilab config init\"\n",
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0Yz4fXaLtbOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import subprocess\n",
        "import time\n",
        "import ibm_boto3\n",
        "from ibm_botocore.client import Config\n",
        "from ibm_botocore.exceptions import ClientError\n",
        "\n",
        "with open('cloud.json', 'r') as f:\n",
        "    jsonCloud = json.load(f)\n",
        "\n",
        "# Check COS Access Here\n",
        "print(\"Set up COS storage and check access\")\n",
        "\n",
        "# IBM Cloud Object Storage credentials\n",
        "cos_id=jsonCloud[\"cos_id\"]\n",
        "cos_api_key=jsonCloud[\"cos_api_key\"]\n",
        "cos_bucket=jsonCloud[\"cos_bucket\"]\n",
        "ibmcloud_region=jsonCloud[\"ibmcloud_region\"]\n",
        "\n",
        "endpoint_url = f'https://s3.{ibmcloud_region}.cloud-object-storage.appdomain.cloud'\n",
        "# Current list of auth_endpoints avaiable at https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints\n",
        "auth_endpoint = 'https://iam.cloud.ibm.com/identity/token'\n",
        "\n",
        "#Create client\n",
        "cos = ibm_boto3.client('s3',\n",
        "                         ibm_api_key_id=cos_api_key,\n",
        "                         ibm_service_instance_id=cos_id,\n",
        "                         ibm_auth_endpoint=auth_endpoint,\n",
        "                         config=Config(signature_version='oauth'),\n",
        "                         endpoint_url=endpoint_url\n",
        "                      )"
      ],
      "metadata": {
        "id": "LHAvkN2xVhqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDUmbbHLvxgg",
        "tags": []
      },
      "source": [
        "<a id=\"IL2_0\"></a>\n",
        "# Section 2. Create Taxonomy\n",
        "\n",
        "\n",
        "This section demonstrates training with InstructLab. This section is part of a sequential notebook. Before running this section of the notebook, please ensure that you have run the Configuring InstructLab section of this notebook. In this section, we will demonstrate creating a question and answer data file.\n",
        "\n",
        "\n",
        "The steps in this section are as follows:\n",
        "* Step 2.1 Specify the Data for this Run\n",
        "* Step 2.2 Create the Taxonomy Data Repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnOLAXRxvxgh",
        "tags": []
      },
      "source": [
        "<a id=\"IL2_data\"></a>\n",
        "## Step 2.1 Specify the Data for this Run\n",
        "\n",
        "We've provided question-and-answer files for these datasets: \"2024 Oscar Awards Ceremony\", \"Quantum Roadmap and Patterns\" and \"Artificial Intelligence Agents\". Feel free to choose one of these datasets, or select your own custom dataset in the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltRTPBTVvxgh",
        "tags": []
      },
      "source": [
        "### Optionally, Create your own data set for InstructLab\n",
        "\n",
        "You can optionally provide your own InstructLab QNA file for processing in this step.\n",
        "\n",
        "Follow these steps to add your own dataset:\n",
        "1. Create your own qna.yaml file following the directions on the InstructLab taxonomy [readme](https://github.com/instructlab/taxonomy).\n",
        "1. Create a questions.txt file with related sample questions to use on inferencing.\n",
        "1. Add your qna.yaml and sample questions.txt files to the /content/ilab/data/your_content_1 folder or the /content/ilab/data/your_content_2 folder by dragging and dropping them in the desired folder.\n",
        "1. Double click on the /content/ilab/config.json file to edit and specify the qna_location where your data resides within the Dewey Decimal classification system. Close and save the config.json file.\n",
        "1. You can now specify to run with your own data by selecting **Your Content 1** or **Your Content 2** in the next code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olkDUaKfvxgh"
      },
      "outputs": [],
      "source": [
        "# Work with the selected dataset\n",
        "if data_set.value=='2024 Oscars':\n",
        "    use_case=\"oscars\"\n",
        "elif data_set.value=='Quantum':\n",
        "    use_case=\"quantum\"\n",
        "elif data_set.value=='Agentic AI':\n",
        "    use_case=\"agentic_ai\"\n",
        "elif data_set.value=='Your Content 1':\n",
        "    use_case=\"your_content_1\"\n",
        "elif data_set.value=='Your Content 2':\n",
        "    use_case=\"your_content_2\"\n",
        "else:\n",
        "    use_case=\"undefined\"\n",
        "    print(\"ERROR: Undefined data set: \" + data_set.value + \" data\")\n",
        "\n",
        "if use_case!=\"undefined\":\n",
        "    qna_dir=\"data/\" + use_case + \"/\"\n",
        "    print(\"Using \" + data_set.value + \" data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.2 Place the QNA Files in the Taxonomy\n",
        "Place the QNA files in the proper directories.\n"
      ],
      "metadata": {
        "id": "KERRJu_tO2TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all of the files in the use_case directory that begin with QNA\n",
        "print_lines=40\n",
        "for f in os.listdir(qna_dir):\n",
        "    f=f.lower()\n",
        "    if f.startswith('qna'):\n",
        "        qna_file = qna_dir + f\n",
        "        print(\"Show the QNA file: \" + qna_file)\n",
        "        with open(qna_file, 'r') as input_file:\n",
        "            for line_number, line in enumerate(input_file):\n",
        "                if line_number == 0:\n",
        "                    words = line.split()\n",
        "                    print(words)\n",
        "                    qna_location = words[1]\n",
        "                if line_number > print_lines:  # line_number starts at 0.\n",
        "                    break\n",
        "                print(line_number, line, end=\"\")\n",
        "        # Place the QNA file in the proper taxonomy directory if it does not already exist\n",
        "        new_qna_dir = \"/taxonomy\" + qna_location\n",
        "        if os.path.exists(os.getcwd()+new_qna_dir):\n",
        "            print(\"\\nWARNING: QNA file already exists in taxonomy at duplicate location, not inserting\")\n",
        "        else:\n",
        "            print(\"\\nPlace QNA file in taxononmy as: /taxonomy\"+qna_location+\"/qna.yaml\")\n",
        "            shell_command1 = f\"mkdir -p ./taxonomy{qna_location}\"\n",
        "            shell_command2 = f\"cp ./{qna_file} ./taxonomy{qna_location}/qna.yaml\"\n",
        "            !{shell_command1}\n",
        "            !{shell_command2}"
      ],
      "metadata": {
        "id": "-X2p2l9KO1PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.3 Verify the Taxonomy Data Repository\n",
        "Run diff to verify the taxonomy."
      ],
      "metadata": {
        "id": "z2sAO4goK9sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Verify the taxonomy\")\n",
        "!ilab taxonomy diff"
      ],
      "metadata": {
        "id": "CVH7U6aiK-ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5l5m7L_LDV1"
      },
      "source": [
        "# Section 3. Tar and Download the Trained Model\n",
        " Now that we have a model trained on our dataset, we can download the trained model for futher testing and use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx65h6u17SW_"
      },
      "outputs": [],
      "source": [
        "#print(\"Do you want to download the trained model to your local machine?\")\n",
        "#display(download)\n",
        "#print(\"After making your selection, please select and run the following cell\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwwZ4P6n7TDu"
      },
      "source": [
        "Select and run the next cell to download if selected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZsjOChUK7gj"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#if download.value=='Yes':\n",
        "#  files.download(trained_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tggqdEdT5irW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ibmcloud"
      ],
      "metadata": {
        "id": "5rVHEpSm40DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K4lhpzTvxgl",
        "tags": []
      },
      "source": [
        "<a id=\"IL3_conclusion\"></a>\n",
        "# Conclusion\n",
        "\n",
        "This notebook demonstrated utilizing InstructLab for introducing datasets, data generation, model training, and model creation. This notebook produced an InstructLab trained model that was available for inferecing and downloading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63hBXXa0vxgl",
        "tags": []
      },
      "source": [
        "<a id=\"IL3_learn\"></a>\n",
        "# Learn More\n",
        "\n",
        "InstructLab uses a novel synthetic data-based alignment tuning method for Large Language Models introduced in this [paper](https://arxiv.org/abs/2403.01081).\n",
        "\n",
        "This notebook is based on the InstructLab CLI repository available [here](https://github.com/instructlab/instructlab).\n",
        "\n",
        "Contact us by email to ask questions, discuss potential use cases, or schedule a technical deep dive. The contact email is IBM.Research.JupyterLab@ibm.com."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poB7nDmcvxgl"
      },
      "source": [
        "Â© 2025 IBM Corporation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}