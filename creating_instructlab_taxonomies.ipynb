{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7ih7e5O6rX_",
        "tags": []
      },
      "source": [
        "# Creating InstructLab Taxonomies\n",
        "\n",
        "<ul>\n",
        "<li>Contributors: InstructLab team and IBM Research Technology Education team:\n",
        "<li>Questions and support: kochel@us.ibm.com, IBM.Research.JupyterLab@ibm.com\n",
        "<li>Release date: 2025-03-20\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ics9GgZ-6rYB",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Overview\n",
        "This Jupyter notebook facilitates compiling taxonomies for InstructLab, an open source AI project that enables knowledge and skills contributions to Large Language Models (LLMs). This notebook performs the following:\n",
        "1. Accepts one or more of Question and Answer (QNA) files as input\n",
        "1. Places the QNA files in the desired palce in a taxonomy\n",
        "1. Verifies the taxonomy by running the ilab dif function\n",
        "1. Creates a Tar file of the taxonomy that can be used for Synthetic Data Generation\n",
        "1. Downloads the Tar file or provides it to the RedHat AI Instructlab Service\n",
        "\n",
        "This notebook can be run with the free Colab environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_SZDBZgMVa"
      },
      "source": [
        "# Step 1. Clone the Ilab Environment and Present Run Options\n",
        "\n",
        "Replicate the ilab data repository containing the pip requirements and data files.\n",
        "\n",
        "\n",
        "After selecting parameters, the remainder of this notebook can be run either:\n",
        "- Running All Cells by selecting Runtime->Run cell and below\n",
        "- Cell by cell by selecting the arrow on each code cell and running them sequentially.\n",
        "\n",
        "Run this next cell, select the following parameters, then follow the direction in the following cell to run the rest of this notebook.\n",
        "\n",
        "We've provided question-and-answer files for these datasets: \"2024 Oscar Awards Ceremony\", \"Quantum Roadmap and Patterns\" and \"Artificial Intelligence Agents\". Feel free to choose one of these datasets, or select \"Your Content 1\" or \"Your Content 2\" and follow the instructions below to provide your own data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E0Z6oO2L_3I"
      },
      "outputs": [],
      "source": [
        "# Install these items first to avoid a later reset\n",
        "!pip install psutil==7.0.0 pillow==10.4.0 --quiet\n",
        "\n",
        "import os\n",
        "os.chdir('/content/')\n",
        "if os.path.exists(\"ilab\"):\n",
        "    !rm -rf ilab\n",
        "!git clone https://github.com/KenOcheltree/ilab-test.git --quiet --recurse-submodules ilab\n",
        "\n",
        "# Run this second cell to show parameters\n",
        "import ipywidgets as widgets\n",
        "data_set = widgets.ToggleButtons(\n",
        "    options=['2024 Oscars', 'Quantum', 'Agentic AI', 'Your Content 1', 'Your Content 2'],\n",
        "    description='Dataset:', style={\"button_width\": \"auto\"}\n",
        ")\n",
        "print(\"\\nSelect the Dataset for this run:\")\n",
        "display(data_set)\n",
        "print(\"After selecting the parameters, select the next cell and then choose Runtime->Run cell and below\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dmB_IVBPkZ1",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Step 2. Provide the Taxonomy data\n",
        "\n",
        "You may want to run this notebook once with an existing dataset before creating your own to understand the Tasonomy creation flow.\n",
        "\n",
        "You can optionally provide your own InstructLab QNA file for processing in this step. Follow these steps to add your own dataset:\n",
        "1. Create your own qna.yaml file following the directions on the InstructLab taxonomy [readme](https://github.com/instructlab/taxonomy).\n",
        "1. After creating your qna.yaml file, add a comment in the first line that starts with *#Location:* and specifies the location of the file in the taxonomy. For example, a quantum computing qna.yaml file would have the following for the first line:\n",
        "```\n",
        "#location: /knowledge/information/computer_science/quantum_computing'\n",
        "```\n",
        "1. Add your qna.yaml to the /content/ilab/data/your_content_1 folder or the /content/ilab/data/your_content_2 folder by dragging and dropping them in the desired folder.\n",
        "1. If you want to include multiple qna.yaml files in your taxonomy, add a unique identifer \"NNN\" to the name so it is of the form qnaNNN.yaml. Any number of QNA files can be included as long as they have unique names\n",
        "1. You can now specify to run with your own data by selecting **Your Content 1** or **Your Content 2** in the next code cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv5uMvQ-a-ZF",
        "tags": []
      },
      "source": [
        "# Step 3. Complete the Environment Set Up\n",
        "\n",
        "\n",
        "This code cell installs the remainder of the reuired pip packages and takes a few minutes to run.\n",
        "\n",
        "The first half of the cell wraps the code cell output for all following cells for ease of reading.\n",
        "\n",
        "The InstructLab configuration is captured in the *config.yaml* file. This step creates the config.yaml file and sets **taxomony_path = taxonomy** - the root location of the taxonomy is set to the taxonomy folder in instructlab-latest\n",
        "\n",
        "**Note:** Ignore any pip inconsistency errors or warnings in the installation. They are inconsequential to the running of this notebook.\n",
        "\n",
        "**Note** If you perform **Runtime->Run cell and below** on this cell, the rest of notebook will take about 10 minutes to run. After running, it will present a prompt for providing questions to the pre-trained and trained models to test improvements in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX9s4XZx6rYF"
      },
      "outputs": [],
      "source": [
        "# You can run the rest of the notebook by selecting this cell and choosing \"Runtime->Run cell and below\"\n",
        "\n",
        "# Wrap Code cell output\n",
        "from IPython.display import HTML, display\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "# Install the ibmcloud plugin\n",
        "!curl -fsSL https://clis.cloud.ibm.com/install/linux | sh\n",
        "!ibmcloud plugin install ilab -f\n",
        "\n",
        "# Install the rest of the requirements\n",
        "os.chdir('/content/ilab/')\n",
        "print(\"Starting directory: \"+ os.getcwd())\n",
        "!pip install -r requirements.txt --quiet\n",
        "!ilab system info\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import shutil\n",
        "import ruamel.yaml\n",
        "\n",
        "# Initialize ilab\n",
        "base_dir=\"/root/\"\n",
        "taxonomy_path='taxonomy'\n",
        "model_path = \"models/granite-7b-lab-Q4_K_M.gguf\"\n",
        "\n",
        "# Define the file name\n",
        "file_name = \"config.yaml\"\n",
        "if os.path.exists(file_name):\n",
        "    os.remove(file_name)\n",
        "    print(f\"ilab was already initialized. {file_name} has been deleted. Reinitialized\")\n",
        "else:\n",
        "    print(f\"ilab was not initialized yet. {file_name} does not exist.\")\n",
        "\n",
        "# Remove old data\n",
        "if os.path.exists(\"taxonomy\"):\n",
        "    print(\"removing taxonomy\")\n",
        "    shutil.rmtree(\"taxonomy\")\n",
        "if os.path.exists(base_dir+\".cache/instructlab\"):\n",
        "    print(\"removing \" + base_dir+\".cache/instructlab\")\n",
        "    shutil.rmtree(base_dir+\".cache/instructlab\")\n",
        "if os.path.exists(base_dir+\".config/instructlab\"):\n",
        "    print(\"removing \" + base_dir+\".config/instructlab\")\n",
        "    shutil.rmtree(base_dir+\".config/instructlab\")\n",
        "if os.path.exists(base_dir+\".local/share/instructlab\"):\n",
        "    print(\"removing \" + base_dir+\".local/share/instructlab\")\n",
        "    shutil.rmtree(base_dir+\".local/share/instructlab\")\n",
        "\n",
        "# Initialize local instructlab isntall\n",
        "print(\"Initialized ilab\")\n",
        "command = f\"\"\"\n",
        "ilab config init<<EOF\n",
        "{taxonomy_path}\n",
        "Y\n",
        "{model_path}\n",
        "0\n",
        "EOF\n",
        "\"\"\"\n",
        "# Using the ! operator to run the command\n",
        "!echo \"Running ilab config init\"\n",
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. Initialize Red Hat AI InstructLab Access"
      ],
      "metadata": {
        "id": "pbw25B-4yrc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initialize Red Hat AI InstructLab Access\")\n",
        "print(\"Installing the IBMCloud ilab plugin as needed\")\n",
        "\n",
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "import time\n",
        "import ibm_boto3\n",
        "from ibm_botocore.client import Config\n",
        "from ibm_botocore.exceptions import ClientError\n",
        "\n",
        "# Replace the following with the use of secrets\n",
        "with open('cloud.json', 'r') as f:\n",
        "    jsonCloud = json.load(f)\n",
        "ibmcloud_key=jsonCloud[\"ibmcloud_key\"]\n",
        "ibmcloud_region=jsonCloud[\"ibmcloud_region\"]\n",
        "ibmcloud_resource=jsonCloud[\"ibmcloud_resource\"]\n",
        "cos_id=jsonCloud[\"cos_id\"]\n",
        "cos_api_key=jsonCloud[\"cos_api_key\"]\n",
        "cos_bucket=jsonCloud[\"cos_bucket\"]\n",
        "\n",
        "!ibmcloud config --check-version=false\n",
        "shell_command = f\"ibmcloud login -apikey {ibmcloud_key} -r {ibmcloud_region} -g {ibmcloud_resource}\"\n",
        "!{shell_command}\n",
        "\n",
        "# !ibmcloud resource service-instances --service-name instructlab --long\n",
        "proj_index=0\n",
        "response = subprocess.check_output(\"ibmcloud resource service-instances --service-name instructlab --long\", shell=True).decode(\"utf-8\").split()\n",
        "for index, word in enumerate(response):\n",
        "    if word == \"GUID:\":\n",
        "        proj_index=index+1\n",
        "        break\n",
        "if proj_index==0:\n",
        "    print(\"Assign project-id\")\n",
        "    !ibmcloud resource service-instance-create 'instructlab' instructlab instructlab-pricing-plan us-east\n",
        "    for index, word in enumerate(response):\n",
        "        if word == \"GUID:\":\n",
        "            proj_index=index+1\n",
        "            break\n",
        "if proj_index==0:\n",
        "    print(\"ERROR in assigning Project ID\")\n",
        "project_id=response[proj_index]\n",
        "\n",
        "shell_command = f\"ibmcloud ilab config set project-id {project_id}\"\n",
        "!{shell_command}\n",
        "\n",
        "print(\"Check IBM Cloud COS authorization policies\")\n",
        "!ibmcloud iam authorization-policies\n",
        "\n",
        "# Set up COS Access Here\n",
        "print(\"Set up COS storage and check access\")\n",
        "endpoint_url = f'https://s3.{ibmcloud_region}.cloud-object-storage.appdomain.cloud'\n",
        "# Current list of auth_endpoints is at https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints\n",
        "auth_endpoint = 'https://iam.cloud.ibm.com/identity/token'\n",
        "#Create client\n",
        "cos = ibm_boto3.client('s3',\n",
        "                         ibm_api_key_id=cos_api_key,\n",
        "                         ibm_service_instance_id=cos_id,\n",
        "                         ibm_auth_endpoint=auth_endpoint,\n",
        "                         config=Config(signature_version='oauth'),\n",
        "                         endpoint_url=endpoint_url\n",
        "                      )"
      ],
      "metadata": {
        "id": "vANOrWuwTAFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4. Create the Taxonomy with the QNA Files\n",
        "Place the QNA files in the proper directories of the taxonomy.\n"
      ],
      "metadata": {
        "id": "KERRJu_tO2TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the folder for the dataset\n",
        "use_cases = {\"2024 Oscars\": \"oscars\", \"Quantum\": \"quantum\", \"Agentic AI\": \"agentic_ai\",\n",
        "            \"Your Content 1\": \"your_content_1\", \"Your Content 2\": \"your_content_2\"}\n",
        "use_case = use_cases[data_set.value]\n",
        "qna_dir = \"data/\" + use_case + \"/\"\n",
        "print(\"Using \" + data_set.value + \" data in folder \" + qna_dir)\n",
        "\n",
        "# List all of the files in the use_case directory that begin with QNA\n",
        "print_lines=30\n",
        "for f in os.listdir(qna_dir):\n",
        "    f=f.lower()\n",
        "    if f.startswith('qna'):\n",
        "        qna_file = qna_dir + f\n",
        "        print(\"Show the QNA file: \" + qna_file)\n",
        "        with open(qna_file, 'r') as input_file:\n",
        "            for line_number, line in enumerate(input_file):\n",
        "                if line_number == 0:\n",
        "                    words = line.split()\n",
        "                    print(words)\n",
        "                    if words[0] == \"#Location:\" and len(words) == 2:\n",
        "                      qna_location = words[1]\n",
        "                    else:\n",
        "                      print(\"ERROR: No specificed location found in QNA File: \" + qna_file)\n",
        "                      break\n",
        "                if line_number > print_lines:  # line_number starts at 0.\n",
        "                    break\n",
        "                print(line_number, line, end=\"\")\n",
        "        # Place the QNA file in the proper taxonomy directory if it does not already exist\n",
        "        new_qna_dir = \"/taxonomy\" + qna_location\n",
        "        if os.path.exists(os.getcwd()+new_qna_dir):\n",
        "            print(\"\\nWARNING: QNA file already exists in taxonomy at duplicate location, not inserting\")\n",
        "        else:\n",
        "            print(\"\\nPlace QNA file in taxononmy as: /taxonomy\"+qna_location+\"/qna.yaml\")\n",
        "            shell_command1 = f\"mkdir -p ./taxonomy{qna_location}\"\n",
        "            shell_command2 = f\"cp ./{qna_file} ./taxonomy{qna_location}/qna.yaml\"\n",
        "            !{shell_command1}\n",
        "            !{shell_command2}"
      ],
      "metadata": {
        "id": "-X2p2l9KO1PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. Verify the Taxonomy Data Repository\n",
        "Run diff to verify the taxonomy. Record the errors on this step and correct them in your QNA files and then rerun the notebook with the corrected QNA files."
      ],
      "metadata": {
        "id": "z2sAO4goK9sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Verify the taxonomy\")\n",
        "!ilab taxonomy diff"
      ],
      "metadata": {
        "id": "CVH7U6aiK-ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5l5m7L_LDV1"
      },
      "source": [
        "# Step 6. Add the Taxonomy to the Cloud\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx65h6u17SW_"
      },
      "outputs": [],
      "source": [
        "set_name=use_case\n",
        "tax_dir= os.getcwd()+\"/taxonomy\"\n",
        "shell_command = f\"ibmcloud ilab taxonomy add --name {set_name} --taxonomy-path {tax_dir} \\\n",
        "--cos-endpoint https://s3.us-east.cloud-object-storage.appdomain.cloud \\\n",
        "--cos-id {cos_id} \\\n",
        "--cos-bucket {cos_bucket}\"\n",
        "\n",
        "print(\"Step 3. Add the taxonomy to the cloud\")\n",
        "tax_response = subprocess.check_output(shell_command, shell=True)\n",
        "print(\"Taxonomy added\")\n",
        "\n",
        "response= tax_response.decode(\"utf-8\").split()\n",
        "for index, word in enumerate(response):\n",
        "    if word == \"id\":\n",
        "        break\n",
        "tax_id = response[index+1]\n",
        "\n",
        "print(\"taxonomy id = \" + tax_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63hBXXa0vxgl",
        "tags": []
      },
      "source": [
        "<a id=\"IL3_learn\"></a>\n",
        "# Learn More\n",
        "\n",
        "InstructLab uses a novel synthetic data-based alignment tuning method for Large Language Models introduced in this [paper](https://arxiv.org/abs/2403.01081).\n",
        "\n",
        "This notebook is based on the InstructLab CLI repository available [here](https://github.com/instructlab/instructlab).\n",
        "\n",
        "Contact us by email to ask questions, discuss potential use cases, or schedule a technical deep dive. The contact email is IBM.Research.JupyterLab@ibm.com."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poB7nDmcvxgl"
      },
      "source": [
        "Â© 2025 IBM Corporation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}