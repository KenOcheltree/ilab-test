{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7ih7e5O6rX_",
        "tags": []
      },
      "source": [
        "# Creating InstructLab Taxonomies\n",
        "\n",
        "<ul>\n",
        "<li>Contributors: InstructLab team and IBM Research Technology Education team\n",
        "<li>Questions and support: kochel@us.ibm.com, IBM.Research.JupyterLab@ibm.com\n",
        "<li>Release date: 2025-05-06\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ics9GgZ-6rYB",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Overview\n",
        "This Jupyter notebook simplifies the compilation of taxonomies for the Red Hat AI InstructLab (RHAIL) service, an AI project that facilitates knowledge and skills contributions to Large Language Models (LLMs). This notebook performs the following:\n",
        "1. Accepts one or more of Question and Answer (QNA) files as input\n",
        "1. Performs `yamllint` checks on the QNA files to verify their format\n",
        "1. Places the QNA files in the desired structure in a taxonomy\n",
        "1. Verifies the taxonomy by running the `ilab diff` function\n",
        "1. Creates a `tar` file of the taxonomy and provides it to the Red Hat AI InstructLab service for synthetic data generation\n",
        "\n",
        "This notebook can be run within the free Colab environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Before You Begin\n",
        "\n",
        "- If you don't have one already, create a [Cloud Object Storage bucket](https://cloud.ibm.com/docs/instructlab?topic=instructlab-storage).\n",
        "- If you are using the service for the first time, complete the [Assigning access](https://cloud.ibm.com/docs/instructlab?topic=instructlab-iam) steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_SZDBZgMVa"
      },
      "source": [
        "# Step 1. Clone the Instructlab Environment and Select Run Options\n",
        "\n",
        "The cell replicates an `ilab` data repository containing the pip requirements and data files, and then presents options for running the notebook.\n",
        "\n",
        "After selecting the parameters, the remainder of this notebook can be run by either:\n",
        "- Running all cells by selecting `Runtime`->`Run cell and below`.\n",
        "- Running each cell sequentially by clicking <img src=\"./refs/run-cell.png\" width=23> **Run cell** by each code cell.\n",
        "\n",
        "Run the following cell, select from the following parameters, and then follow the directions in the cell to run the rest of this notebook.\n",
        "\n",
        "We've provided question and qnswer files for these datasets:\n",
        "- \"2024 Oscar Awards Ceremony\"\n",
        "- \"Quantum Roadmap and Patterns\"\n",
        "- \"Artificial Intelligence Agents\"\n",
        "- \"Multi-QNA Example\": Contains QNA files for Oscars, Quantum, and Agentic AI data sets to show how multiple QNA files can be provided and processed.\n",
        "- \"Your Content 1\" or \"Your Content 2\": Follow the instructions in Step 2.2 to provide your own data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E0Z6oO2L_3I"
      },
      "outputs": [],
      "source": [
        "# Install these items first to avoid a later reset\n",
        "!pip install psutil==7.0.0 pillow==10.4.0 --quiet\n",
        "\n",
        "import os\n",
        "os.chdir('/content/')\n",
        "if os.path.exists(\"ilab\"):\n",
        "    !rm -rf ilab\n",
        "!git clone https://github.com/KenOcheltree/ilab-test.git --quiet --recurse-submodules ilab\n",
        "#Remove the colab sample_data\n",
        "if os.path.exists(\"sample_data\"):\n",
        "    !rm -rf sample_data\n",
        "\n",
        "# Run this second cell to show parameters\n",
        "import ipywidgets as widgets\n",
        "data_set = widgets.ToggleButtons(\n",
        "    options=['2024 Oscars', 'Quantum', 'Agentic AI', 'Multi-QNA Example', 'Your Content 1', 'Your Content 2'],\n",
        "    description='Dataset:', style={\"button_width\": \"auto\"}\n",
        ")\n",
        "print(\"\\nSelect the Dataset for this run:\")\n",
        "display(data_set)\n",
        "print(\"After selecting the dataset, select the next cell and then choose Runtime->Run cell and below\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dmB_IVBPkZ1",
        "tags": []
      },
      "source": [
        "# Step 2. Prepare to Create the Taxonomy\n",
        "\n",
        "## 2.1 Store Your IBM Cloud and COS Access Credentials in Secrets\n",
        "\n",
        "When you configure IBM Cloud and Cloud Object Storage (COS) access to use with the Red Hat AI InstructLab service, you must provide access keys and resource IDs to provide to upload your taxonomy. Set the following parameters in the secrets area.\n",
        "\n",
        "Click the Secrets icon in the sidebar, which looks like a key and give the notebook access to each of these parameters:\n",
        "\n",
        "- **ibmcloud_key**: An [API key](https://cloud.ibm.com/iam/apikeys) to access your IBM Cloud account.  Example: \"XX_XXXXXXXXXXXXXXXXXX\"\n",
        "- **ibmcloud_region**: The IBM Cloud region. Example: `us-east`\n",
        "- **ibmcloud_resource_group**: The [resource group](https://cloud.ibm.com/account/resource-groups). Example: `default`\n",
        "- **project_id**: A project identifer. Example: `InstructLab`\n",
        "- **cos_bucket**: The name of the COS bucket. The bucket it where the taxonomy is stored. If you do not have one yet, the bucket is created for you. Example: `ilabdata`\n",
        "- **cos_endpoint**: The COS endpoint. Example: `https://s3.us-east.cloud-object-storage.appdomain.cloud`\n",
        "\n",
        "\n",
        "## 2.2 Optional: Provide Your Own Taxonomy Data\n",
        "\n",
        "You might want to run this notebook once with an existing data set before creating your own to understand the taxonomy creation flow.\n",
        "\n",
        "You can provide your own InstructLab QNA file for processing in this step.\n",
        "1. Create your own `qna.yaml` file by following the directions in the InstructLab taxonomy [readme](https://github.com/instructlab/taxonomy).\n",
        "1. After creating your `qna.yaml` file, add a comment in the first line that starts with `# Location:` and specifies the location of the file in the taxonomy. For example, a quantum computing `qna.yaml` file has the following path for the location:\n",
        "    ```\n",
        "    # location: /knowledge/information/computer_science/quantum_computing\n",
        "    ```\n",
        "1. Add your `qna.yaml` to the `/content/ilab/data/your_content_1` folder or the `/content/ilab/data/your_content_2` folder by dragging and dropping it into the folder.\n",
        "1. To include multiple `qna.yaml` files in your taxonomy, add a unique identifer `NNN` to the name so it is of the format `qnaNNN.yaml`. Any number of QNA files can be included as long as they have unique names.\n",
        "1. You can use your own data by selecting **Your Content 1** or **Your Content 2** in the code cell.\n",
        "\n",
        "\n",
        "## 2.3 Complete the Environment Set Up\n",
        "\n",
        "This code cell installs the remainder of the required pip packages and configures InstructLab. The InstructLab configuration is captured in the `config.yaml` file. The `config.yaml` file is created for you and `taxomony_path = taxonomy` is set. The root location of the taxonomy is set to the taxonomy folder in `instructlab-latest`.\n",
        "\n",
        "**Note:** \n",
        "- This step can take a few minutes to run. If you are running all of the cells at the same time, it can take 10 minutes to run.\n",
        "- Ignore any pip inconsistency errors or warnings in the installation. They do not affect the running of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX9s4XZx6rYF"
      },
      "outputs": [],
      "source": [
        "# You can run the rest of the notebook by selecting this cell and choosing \"Runtime->Run cell and below\"\n",
        "\n",
        "# Acquire access to secret keys\n",
        "from google.colab import userdata\n",
        "\n",
        "# Wrap Code cell output\n",
        "from IPython.display import HTML, display\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "# Install the ibmcloud plugin\n",
        "!curl -fsSL https://clis.cloud.ibm.com/install/linux | sh\n",
        "!ibmcloud plugin install ilab -f\n",
        "\n",
        "# Install the rest of the requirements\n",
        "os.chdir('/content/ilab/')\n",
        "print(\"Starting directory: \"+ os.getcwd())\n",
        "!pip install -r requirements.txt --quiet\n",
        "!ilab system info\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import shutil\n",
        "\n",
        "# Initialize ilab\n",
        "base_dir=\"/root/\"\n",
        "taxonomy_path='taxonomy'\n",
        "model_path = \"models/granite-7b-lab-Q4_K_M.gguf\"\n",
        "\n",
        "# Remove old ilab configuration data\n",
        "if os.path.exists(base_dir+\".config/instructlab\"):\n",
        "    print(\"removing \" + base_dir+\".config/instructlab\")\n",
        "    shutil.rmtree(base_dir+\".config/instructlab\")\n",
        "if os.path.exists(base_dir+\".local/share/instructlab\"):\n",
        "    print(\"removing \" + base_dir+\".local/share/instructlab\")\n",
        "    shutil.rmtree(base_dir+\".local/share/instructlab\")\n",
        "\n",
        "# Initialize local instructlab isntall\n",
        "print(\"Initialized ilab\")\n",
        "command = f\"\"\"\n",
        "ilab config init<<EOF\n",
        "{taxonomy_path}\n",
        "Y\n",
        "{model_path}\n",
        "0\n",
        "EOF\n",
        "\"\"\"\n",
        "# Using the ! operator to run the command\n",
        "!echo \"Running ilab config init\"\n",
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbw25B-4yrc3"
      },
      "source": [
        "# Step 3. Initialize Red Hat AI InstructLab Service Access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vANOrWuwTAFA"
      },
      "outputs": [],
      "source": [
        "print(\"Initialize Red Hat AI InstructLab Service Access\")\n",
        "print(\"Installing the IBMCloud ilab plugin\")\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Pull data from secrets\n",
        "ibmcloud_key=userdata.get(\"ibmcloud_key\")\n",
        "ibmcloud_region=userdata.get(\"ibmcloud_region\")\n",
        "ibmcloud_resource_group=userdata.get(\"ibmcloud_resource_group\")\n",
        "cos_bucket=userdata.get(\"cos_bucket\")\n",
        "cos_endpoint=userdata.get(\"cos_endpoint\")\n",
        "try:\n",
        "    project_id=userdata.get(\"project_id\")\n",
        "except:\n",
        "    project_id=\"InstructLab\"\n",
        "\n",
        "!ibmcloud config --check-version=false\n",
        "shell_command = f\"ibmcloud login -apikey {ibmcloud_key} -r {ibmcloud_region} -g {ibmcloud_resource_group}\"\n",
        "!{shell_command}\n",
        "\n",
        "# !ibmcloud resource service-instances --service-name instructlab --long\n",
        "proj_index=0\n",
        "response = subprocess.check_output(\"ibmcloud resource service-instances --service-name instructlab --long\", shell=True).decode(\"utf-8\").split()\n",
        "print(\"Response: \",response)\n",
        "for index, word in enumerate(response):\n",
        "    if word == \"GUID:\" and response[index+3]==project_id:\n",
        "        print(\"Project ID Found\")\n",
        "        proj_index=index+1\n",
        "        break\n",
        "if proj_index==0:\n",
        "    print(\"Assign project-id\")\n",
        "    response = subprocess.check_output(\"ibmcloud resource service-instance-create 'InstructLab' instructlab instructlab-pricing-plan \"+ibmcloud_region,\n",
        "        shell=True).decode(\"utf-8\").split()\n",
        "    for index, word in enumerate(response):\n",
        "        if word == \"GUID:\":\n",
        "            proj_index=index+1\n",
        "            break\n",
        "if proj_index==0:\n",
        "    print(\"ERROR in assigning Project ID\")\n",
        "project_index=response[proj_index]\n",
        "print(\"Project Index: \" + project_index)\n",
        "\n",
        "shell_command = f\"ibmcloud ilab config set project-id {project_index}\"\n",
        "!{shell_command}\n",
        "\n",
        "print(\"Check IBM Cloud COS authorization policies\")\n",
        "!ibmcloud iam authorization-policies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O2uP8Fm26EK"
      },
      "source": [
        "\n",
        "# Step 4. Check the Format of the QNA YAML Files\n",
        "\n",
        "Running this cell checks the format of the YAML files before they are placed in the taxonomy to ensure they are the right length and there are no trailing blanks.\n",
        "\n",
        "For each QNA file, the YAML file checker outputs a `Checking File: QNA.yaml` header followed by a list of errors found in the file. There is no other output besides the header for properly configured files.\n",
        "\n",
        "**Important:** Rerun the following cell until all of the QNA files pass the `yamllint` test. Otherwise,synthetic data generation steps fail later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgS0Z9V926-Y"
      },
      "outputs": [],
      "source": [
        "import yamllint\n",
        "# Select the folder of the dataset\n",
        "use_cases = {\"2024 Oscars\": \"oscars\", \"Quantum\": \"quantum\", \"Agentic AI\": \"agentic_ai\",\n",
        "            \"Multi-QNA Example\": \"example\",\"Your Content 1\": \"your_content_1\", \"Your Content 2\": \"your_content_2\"}\n",
        "use_case = use_cases[data_set.value]\n",
        "qna_dir = \"data/\" + use_case + \"/\"\n",
        "print(\"Running yaml checker on \" + data_set.value + \" data in folder \" + qna_dir)\n",
        "for f in os.listdir(qna_dir):\n",
        "    f=f.lower()\n",
        "    if f.startswith('qna'):\n",
        "      print(\"Checking File: \" + f)\n",
        "      yaml_file = qna_dir + f\n",
        "      shell_command = f\"yamllint /content/ilab/{yaml_file} -c /content/ilab/yamlrules.yaml\"\n",
        "      !{shell_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KERRJu_tO2TM"
      },
      "source": [
        "# Step 5. Create the Taxonomy with the QNA Files\n",
        "Running this next cell places the QNA files in the proper directories of the taxonomy.\n",
        "\n",
        "If you want to add additional QNA files to the taxonomy after the following cell is run, you can create the necessary levels of directories and add the `qna.yaml` named file directly to the taxonomy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X2p2l9KO1PA"
      },
      "outputs": [],
      "source": [
        "# List all of the files in the use_case directory that begin with QNA\n",
        "print_lines=30\n",
        "for f in os.listdir(qna_dir):\n",
        "    f=f.lower()\n",
        "    if f.startswith('qna'):\n",
        "        qna_file = qna_dir + f\n",
        "        print(\"Show the QNA file: \" + qna_file)\n",
        "        with open(qna_file, 'r') as input_file:\n",
        "            for line_number, line in enumerate(input_file):\n",
        "                if line_number == 0:\n",
        "                    words = line.split()\n",
        "                    print(\"Checking first line of QNA file for placement location: \" + line)\n",
        "                    if words[0] == \"#\" and words[1] == \"location:\" and len(words) == 3:\n",
        "                      qna_location = words[2]\n",
        "                    else:\n",
        "                      print(\"ERROR: Placement location not specified in QNA File: \" + qna_file)\n",
        "                      break\n",
        "                if line_number > print_lines:  # line_number starts at 0.\n",
        "                    break\n",
        "                print(line_number, line, end=\"\")\n",
        "        # Place the QNA file in the proper taxonomy directory if it does not already exist\n",
        "        new_qna_dir = \"/taxonomy\" + qna_location\n",
        "        if os.path.exists(os.getcwd()+new_qna_dir):\n",
        "            print(\"\\nWARNING: QNA file already exists in the taxonomy at duplicate location, not inserting\")\n",
        "        else:\n",
        "            print(\"\\nPlace QNA file in taxononmy as: /taxonomy\"+qna_location+\"/qna.yaml\")\n",
        "            shell_command1 = f\"mkdir -p ./taxonomy{qna_location}\"\n",
        "            shell_command2 = f\"cp ./{qna_file} ./taxonomy{qna_location}/qna.yaml\"\n",
        "            !{shell_command1}\n",
        "            !{shell_command2}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2sAO4goK9sO"
      },
      "source": [
        "# Step 6. Verify the Taxonomy Data Repository\n",
        "Run the `diff` command to verify the taxonomy. Record the errors from this step and correct them in your QNA files. Then rerun the notebook with the corrected QNA files.\n",
        "\n",
        "For a properly configured taxonomy, the last line of the output reads:\n",
        "\n",
        "  \"Taxonomy in taxonomy is valid :)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVH7U6aiK-ds"
      },
      "outputs": [],
      "source": [
        "print(\"Verify the taxonomy\")\n",
        "!ilab -vvv taxonomy diff --taxonomy-path taxonomy --taxonomy-base empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5l5m7L_LDV1"
      },
      "source": [
        "# Step 7. Add the Taxonomy to the Cloud\n",
        "\n",
        "If you receive an error running this code cell:\n",
        "- Check your credentials added into the Colab secrets.\n",
        "- Verify that the COS bucket is already created.\n",
        "- Verify that you have the proper access.\n",
        "\n",
        "After you make the corrections, run the notebook again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx65h6u17SW_"
      },
      "outputs": [],
      "source": [
        "set_name=use_case\n",
        "tax_dir= os.getcwd()+\"/taxonomy\"\n",
        "shell_command = f\"ibmcloud ilab taxonomy add --name {set_name} --taxonomy-path {tax_dir} \\\n",
        "--cos-endpoint {cos_endpoint} --cos-bucket {cos_bucket}\"\n",
        "\n",
        "print(\"Add the taxonomy to the cloud\")\n",
        "tax_response = subprocess.check_output(shell_command, shell=True)\n",
        "print(\"Taxonomy added\")\n",
        "\n",
        "response= tax_response.decode(\"utf-8\").split()\n",
        "for index, word in enumerate(response):\n",
        "    if word == \"id\":\n",
        "        break\n",
        "tax_id = response[index+1]\n",
        "\n",
        "print(\"taxonomy id = \" + tax_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63hBXXa0vxgl",
        "tags": []
      },
      "source": [
        "<a id=\"IL3_learn\"></a>\n",
        "# Learn More\n",
        "\n",
        "InstructLab uses a novel synthetic data-based alignment tuning method for Large Language Models introduced in this [paper](https://arxiv.org/abs/2403.01081).\n",
        "\n",
        "Contact us by email to ask questions, discuss potential use cases, or schedule a technical deep dive. The contact email is IBM.Research.JupyterLab@ibm.com."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poB7nDmcvxgl"
      },
      "source": [
        "© 2025 IBM Corporation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
