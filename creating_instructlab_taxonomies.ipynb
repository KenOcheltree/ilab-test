{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7ih7e5O6rX_",
        "tags": []
      },
      "source": [
        "# Creating InstructLab Taxonomies\n",
        "\n",
        "<ul>\n",
        "<li>Contributors: InstructLab team and IBM Research Technology Education team:\n",
        "<li>Questions and support: kochel@us.ibm.com, IBM.Research.JupyterLab@ibm.com\n",
        "<li>Release date: 2025-05-06\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ics9GgZ-6rYB",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Overview\n",
        "This Jupyter notebook simplifies the compilation of taxonomies for the Red Hat AI InstructLab (RHAIL) service, an AI project that facilitates knowledge and skills contributions to Large Language Models (LLMs). This notebook performs the following:\n",
        "1. Accepts one or more of Question and Answer (QNA) files as input\n",
        "1. Performs yamllint checks on the QNA files to verify their formant\n",
        "1. Places the QNA files in the desired palce in a taxonomy\n",
        "1. Verifies the taxonomy by running the ilab diff function\n",
        "1. Creates a Tar file of the taxonomy and provides it to the Red Hat AI InstructLab service for Synthetic Data Generation\n",
        "\n",
        "This notebook can be run within the free Colab environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_SZDBZgMVa"
      },
      "source": [
        "# Step 1. Clone the Instructlab Environment and Present Run Options\n",
        "\n",
        "The cell replicates the ilab data repository containing the pip requirements and data files and present options for running the notebook.\n",
        "\n",
        "\n",
        "After selecting parameters, the remainder of this notebook can be run either:\n",
        "- Running All Cells by selecting Runtime->Run cell and below\n",
        "- Cell by cell by selecting the arrow on each code cell and running them sequentially.\n",
        "\n",
        "Run this next cell, select the following parameters, then follow the direction in the following cell to run the rest of this notebook.\n",
        "\n",
        "We've provided Question and Answer files for these datasets: \"2024 Oscar Awards Ceremony\", \"Quantum Roadmap and Patterns\" and \"Artificial Intelligence Agents\".\n",
        "\n",
        "The \"Multi-QNA Example\" dataset contains QNA files for Oscars, Quantum and Agentic AI to show now multiple QNA files can be provided and processed.\n",
        "\n",
        "Feel free to choose one of these datasets, or select \"Your Content 1\" or \"Your Content 2\" and follow the instructions below to provide your own data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E0Z6oO2L_3I"
      },
      "outputs": [],
      "source": [
        "# Install these items first to avoid a later reset\n",
        "!pip install psutil==7.0.0 pillow==10.4.0 --quiet\n",
        "\n",
        "import os\n",
        "os.chdir('/content/')\n",
        "if os.path.exists(\"ilab\"):\n",
        "    !rm -rf ilab\n",
        "!git clone https://github.com/KenOcheltree/ilab-test.git --quiet --recurse-submodules ilab\n",
        "#Remove the colab sample_data\n",
        "if os.path.exists(\"sample_data\"):\n",
        "    !rm -rf sample_data\n",
        "\n",
        "# Run this second cell to show parameters\n",
        "import ipywidgets as widgets\n",
        "data_set = widgets.ToggleButtons(\n",
        "    options=['2024 Oscars', 'Quantum', 'Agentic AI', 'Multi-QNA Example', 'Your Content 1', 'Your Content 2'],\n",
        "    description='Dataset:', style={\"button_width\": \"auto\"}\n",
        ")\n",
        "print(\"\\nSelect the Dataset for this run:\")\n",
        "display(data_set)\n",
        "print(\"After selecting the dataset, select the next cell and then choose Runtime->Run cell and below\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dmB_IVBPkZ1",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "#Step 2. Prepare for Creating the Taxonomy\n",
        "\n",
        "## 2.1 Place your IBM Cloud and COS Access Credentials in Secrets\n",
        "\n",
        "When you configured IBM Cloud and COS access, you will have access keys and resource IDs that you need to provide to upload your taxonomy to the Red Hat AI InstructLab service. You need to set the following paramters in your secrets area (accessed by selecting the key icon on the left). Be sure to give notebook access to each of these parameters:\n",
        "\n",
        "- **ibmcloud_key** - a key to access your IBM Cloud account of the form \"XX_XXXXXXXXXXXXXXXXXX\"\n",
        "- **ibmcloud_region** - a value specifying your IBM Cloud region of the form \"us-east\"\n",
        "- **ibmcloud_resource_group** - a designator for yout resource of the form \"InstructLab\"\n",
        "- **project_id** - the project identifer for this work. We will use \"InstructLab\" as a default if one is not specified. We will create a new project if one with the desired name does not already exist.\n",
        "- **cos_bucket** - the name of your COS bucket of the form \"ilabdata\"\n",
        "- **cos_endpoint** - the location of the COS endpoint of the form \"https://s3.us-east.cloud-object-storage.appdomain.cloud\"\n",
        "\n",
        "## 2.2 Provide the Taxonomy data\n",
        "\n",
        "You may want to run this notebook once with an existing dataset before creating your own to understand the Tasonomy creation flow.\n",
        "\n",
        "You can optionally provide your own InstructLab QNA file for processing in this step. Follow these steps to add your own dataset:\n",
        "1. Create your own qna.yaml file following the directions on the InstructLab taxonomy [readme](https://github.com/instructlab/taxonomy).\n",
        "1. After creating your qna.yaml file, add a comment in the first line that starts with *# Location:* and specifies the location of the file in the taxonomy. For example, a quantum computing qna.yaml file would have the following for the first line:\n",
        "```\n",
        "# location: /knowledge/information/computer_science/quantum_computing'\n",
        "```\n",
        "1. Add your qna.yaml to the /content/ilab/data/your_content_1 folder or the /content/ilab/data/your_content_2 folder by dragging and dropping them in the desired folder.\n",
        "1. If you want to include multiple qna.yaml files in your taxonomy, add a unique identifer \"NNN\" to the name so it is of the form qnaNNN.yaml. Any number of QNA files can be included as long as they have unique names\n",
        "1. You can now specify to run with your own data by selecting **Your Content 1** or **Your Content 2** in the next code cell.\n",
        "\n",
        "##2.3 Complete the Environment Set Up\n",
        "\n",
        "\n",
        "This code cell installs the remainder of the required pip packages aond configures InstructLab, taking a few minutes to run. The InstructLab configuration is captured in the *config.yaml* file. This step creates the config.yaml file and sets **taxomony_path = taxonomy** - the root location of the taxonomy is set to the taxonomy folder in instructlab-latest\n",
        "\n",
        "**Note:** Ignore any pip inconsistency errors or warnings in the installation. They are inconsequential to the running of this notebook.\n",
        "\n",
        "**Note:** If you perform **Runtime->Run cell and below** on this cell, the rest of notebook will take about 10 minutes to run. After running, it will present a prompt for providing questions to the pre-trained and trained models to test improvements in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX9s4XZx6rYF"
      },
      "outputs": [],
      "source": [
        "# You can run the rest of the notebook by selecting this cell and choosing \"Runtime->Run cell and below\"\n",
        "\n",
        "# Acquire access to secret keys\n",
        "from google.colab import userdata\n",
        "\n",
        "# Wrap Code cell output\n",
        "from IPython.display import HTML, display\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "# Install the ibmcloud plugin\n",
        "!curl -fsSL https://clis.cloud.ibm.com/install/linux | sh\n",
        "!ibmcloud plugin install ilab -f\n",
        "\n",
        "# Install the rest of the requirements\n",
        "os.chdir('/content/ilab/')\n",
        "print(\"Starting directory: \"+ os.getcwd())\n",
        "!pip install -r requirements.txt --quiet\n",
        "!ilab system info\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import shutil\n",
        "\n",
        "# Initialize ilab\n",
        "base_dir=\"/root/\"\n",
        "taxonomy_path='taxonomy'\n",
        "model_path = \"models/granite-7b-lab-Q4_K_M.gguf\"\n",
        "\n",
        "# Remove old ilab configuration data\n",
        "if os.path.exists(base_dir+\".local/share/instructlab\"):\n",
        "    print(\"removing \" + base_dir+\".local/share/instructlab\")\n",
        "    shutil.rmtree(base_dir+\".local/share/instructlab\")\n",
        "\n",
        "# Initialize local instructlab isntall\n",
        "print(\"Initialized ilab\")\n",
        "command = f\"\"\"\n",
        "ilab config init<<EOF\n",
        "{taxonomy_path}\n",
        "Y\n",
        "{model_path}\n",
        "0\n",
        "EOF\n",
        "\"\"\"\n",
        "# Using the ! operator to run the command\n",
        "!echo \"Running ilab config init\"\n",
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. Initialize Red Hat AI InstructLab Service Access"
      ],
      "metadata": {
        "id": "pbw25B-4yrc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initialize Red Hat AI InstructLab Service Access\")\n",
        "print(\"Installing the IBMCloud ilab plugin\")\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Pull data from secrets\n",
        "ibmcloud_key=userdata.get(\"ibmcloud_key\")\n",
        "ibmcloud_region=userdata.get(\"ibmcloud_region\")\n",
        "ibmcloud_resource_group=userdata.get(\"ibmcloud_resource_group\")\n",
        "cos_bucket=userdata.get(\"cos_bucket\")\n",
        "cos_endpoint=userdata.get(\"cos_endpoint\")\n",
        "try:\n",
        "    project_id=userdata.get(\"project_id\")\n",
        "except:\n",
        "    project_id=\"InstructLab\"\n",
        "\n",
        "!ibmcloud config --check-version=false\n",
        "shell_command = f\"ibmcloud login -apikey {ibmcloud_key} -r {ibmcloud_region} -g {ibmcloud_resource_group}\"\n",
        "!{shell_command}\n",
        "\n",
        "# !ibmcloud resource service-instances --service-name instructlab --long\n",
        "proj_index=0\n",
        "response = subprocess.check_output(\"ibmcloud resource service-instances --service-name instructlab --long\", shell=True).decode(\"utf-8\").split()\n",
        "print(\"Response: \",response)\n",
        "for index, word in enumerate(response):\n",
        "    if word == \"GUID:\" and response[index+3]==project_id:\n",
        "        print(\"Project ID Found\")\n",
        "        proj_index=index+1\n",
        "        break\n",
        "if proj_index==0:\n",
        "    print(\"Assign project-id\")\n",
        "    response = subprocess.check_output(\"ibmcloud resource service-instance-create 'InstructLab' instructlab instructlab-pricing-plan \"+ibmcloud_region,\n",
        "        shell=True).decode(\"utf-8\").split()\n",
        "    for index, word in enumerate(response):\n",
        "        if word == \"GUID:\":\n",
        "            proj_index=index+1\n",
        "            break\n",
        "if proj_index==0:\n",
        "    print(\"ERROR in assigning Project ID\")\n",
        "project_index=response[proj_index]\n",
        "print(\"Project Index: \" + project_index)\n",
        "\n",
        "shell_command = f\"ibmcloud ilab config set project-id {project_index}\"\n",
        "!{shell_command}\n",
        "\n",
        "print(\"Check IBM Cloud COS authorization policies\")\n",
        "!ibmcloud iam authorization-policies"
      ],
      "metadata": {
        "id": "vANOrWuwTAFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 4. Check the Format of the QNA YAML Files\n",
        "\n",
        "Running this cell checks the format of the yaml files before they are placed in the taxonomy to ensure they are the right length and there are no trailing blanks.\n",
        "\n",
        "**Important:** Rerun the following cell until all of the QNA files pass the yamllint test. Otherwise the file will fail in the Synthetic Data Generation step.\n"
      ],
      "metadata": {
        "id": "7O2uP8Fm26EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yamllint\n",
        "# Select the folder of the dataset\n",
        "use_cases = {\"2024 Oscars\": \"oscars\", \"Quantum\": \"quantum\", \"Agentic AI\": \"agentic_ai\",\n",
        "            \"Multi-QNA Example\": \"example\",\"Your Content 1\": \"your_content_1\", \"Your Content 2\": \"your_content_2\"}\n",
        "use_case = use_cases[data_set.value]\n",
        "qna_dir = \"data/\" + use_case + \"/\"\n",
        "print(\"Running yaml checker on \" + data_set.value + \" data in folder \" + qna_dir)\n",
        "for f in os.listdir(qna_dir):\n",
        "    f=f.lower()\n",
        "    if f.startswith('qna'):\n",
        "      print(\"Checking File: \" + f)\n",
        "      yaml_file = qna_dir + f\n",
        "      shell_command = f\"yamllint /content/ilab/{yaml_file} -c /content/ilab/yamlrules.yaml\"\n",
        "      !{shell_command}"
      ],
      "metadata": {
        "id": "ZgS0Z9V926-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. Create the Taxonomy with the QNA Files\n",
        "Running this next cell places the QNA files in the proper directories of the taxonomy.\n",
        "\n",
        "If you want to add additional QNA files to the taxonomy after the following cell is run, you can create the necessary levels of directories and add the qna.yaml named file directly to the taxonomy.\n"
      ],
      "metadata": {
        "id": "KERRJu_tO2TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all of the files in the use_case directory that begin with QNA\n",
        "print_lines=30\n",
        "for f in os.listdir(qna_dir):\n",
        "    f=f.lower()\n",
        "    if f.startswith('qna'):\n",
        "        qna_file = qna_dir + f\n",
        "        print(\"Show the QNA file: \" + qna_file)\n",
        "        with open(qna_file, 'r') as input_file:\n",
        "            for line_number, line in enumerate(input_file):\n",
        "                if line_number == 0:\n",
        "                    words = line.split()\n",
        "                    print(\"Checking first line of QNA file for placement location: \" + line)\n",
        "                    if words[0] == \"#\" and words[1] == \"location:\" and len(words) == 3:\n",
        "                      qna_location = words[2]\n",
        "                    else:\n",
        "                      print(\"ERROR: Placement location not specified in QNA File: \" + qna_file)\n",
        "                      break\n",
        "                if line_number > print_lines:  # line_number starts at 0.\n",
        "                    break\n",
        "                print(line_number, line, end=\"\")\n",
        "        # Place the QNA file in the proper taxonomy directory if it does not already exist\n",
        "        new_qna_dir = \"/taxonomy\" + qna_location\n",
        "        if os.path.exists(os.getcwd()+new_qna_dir):\n",
        "            print(\"\\nWARNING: QNA file already exists in the taxonomy at duplicate location, not inserting\")\n",
        "        else:\n",
        "            print(\"\\nPlace QNA file in taxononmy as: /taxonomy\"+qna_location+\"/qna.yaml\")\n",
        "            shell_command1 = f\"mkdir -p ./taxonomy{qna_location}\"\n",
        "            shell_command2 = f\"cp ./{qna_file} ./taxonomy{qna_location}/qna.yaml\"\n",
        "            !{shell_command1}\n",
        "            !{shell_command2}"
      ],
      "metadata": {
        "id": "-X2p2l9KO1PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6. Verify the Taxonomy Data Repository\n",
        "Run diff to verify the taxonomy. Record the errors on this step and correct them in your QNA files and then rerun the notebook with the corrected QNA files."
      ],
      "metadata": {
        "id": "z2sAO4goK9sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Verify the taxonomy\")\n",
        "!ilab -vvv taxonomy diff --taxonomy-path taxonomy --taxonomy-base empty"
      ],
      "metadata": {
        "id": "CVH7U6aiK-ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5l5m7L_LDV1"
      },
      "source": [
        "# Step 7. Add the Taxonomy to the Cloud\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx65h6u17SW_"
      },
      "outputs": [],
      "source": [
        "set_name=use_case\n",
        "tax_dir= os.getcwd()+\"/taxonomy\"\n",
        "shell_command = f\"ibmcloud ilab taxonomy add --name {set_name} --taxonomy-path {tax_dir} \\\n",
        "--cos-endpoint {cos_endpoint} --cos-bucket {cos_bucket}\"\n",
        "\n",
        "print(\"Add the taxonomy to the cloud\")\n",
        "tax_response = subprocess.check_output(shell_command, shell=True)\n",
        "print(\"Taxonomy added\")\n",
        "\n",
        "response= tax_response.decode(\"utf-8\").split()\n",
        "for index, word in enumerate(response):\n",
        "    if word == \"id\":\n",
        "        break\n",
        "tax_id = response[index+1]\n",
        "\n",
        "print(\"taxonomy id = \" + tax_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63hBXXa0vxgl",
        "tags": []
      },
      "source": [
        "<a id=\"IL3_learn\"></a>\n",
        "# Learn More\n",
        "\n",
        "InstructLab uses a novel synthetic data-based alignment tuning method for Large Language Models introduced in this [paper](https://arxiv.org/abs/2403.01081).\n",
        "\n",
        "Contact us by email to ask questions, discuss potential use cases, or schedule a technical deep dive. The contact email is IBM.Research.JupyterLab@ibm.com."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poB7nDmcvxgl"
      },
      "source": [
        "© 2025 IBM Corporation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}